---
title: "PM 566 Lab 5"
author: "Ziquan 'Harrison' Liu"
format: 
  html:
    embed-resources: true
fig-width: 8
fig-heigth: 6
---
# library package
```{r}
library(dplyr)
library(R.utils)
library(leaflet)
```
# Data Preparation on Station
```{r}
# Download the data
stations <- read.csv("https://noaa-isd-pds.s3.amazonaws.com/isd-history.csv")
stations$USAF <- as.integer(stations$USAF)

# Dealing with blanks and 999999
stations$USAF[stations$USAF == 999999] <- NA
stations$CTRY[stations$CTRY == ""] <- NA
stations$STATE[stations$STATE == ""] <- NA

# Selecting the three relevant columns, and keeping unique records
stations <- unique(stations[, c('USAF', 'CTRY', 'STATE')])

# Dropping NAs
stations <- stations[!is.na(stations$USAF), ]

# Removing duplicates
stations <- stations[!duplicated(stations$USAF), ]
```

```{r}
if (!file.exists("met_all.gz"))
  download.file(
    url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/02_met/met_all.gz",
    destfile = "met_all.gz",
    method   = "libcurl",
    timeout  = 60
    )
met <- data.table::fread("met_all.gz")
```

```{r}
# check duplicate on stations data
stations <- stations[!duplicated(stations$USAF), ]
```

# Processing in met
```{r}
met <- met[met$temp > -17, ]
met$elev[met$elev == 9999.0] <- NA
met$week <- as.numeric(format(as.Date(paste(met$year, met$ month, met$day, sep = "-")), "%U"))
met <- met[met$week == min(met$week,na.rm = T),]
met_avg <- aggregate(cbind(temp,rh,wind.sp,vis.dist,dew.point,lat,lon,elev,atm.press)~USAFID, data = met, FUN = mean,
                     na.ro = TRUE)
met_avg$region <- ifelse(met_avg$lon > -98 & met_avg$lat >39.71, "north east",
                         ifelse(met_avg$lon > -98 & met_avg$lat < 39.71, "south east",
                                ifelse(met_avg$lon < -98 & met_avg$lat >39.71, "north west", "south west")))
met_avg$elev_cat <- ifelse(met_avg$elev> 252, "high", "low")
```

```{r}
met_stations <- merge(
  # Data
  x     = met_avg,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF"
  )
```

# Question 1
```{r}
temp_median <- quantile(met_avg$temp, 0.5, na.rm = TRUE)
wind_median <- quantile(met_avg$wind.sp, 0.5, na.rm = TRUE)
atm_median <- quantile(met_avg$atm.press, 0.5, na.rm = TRUE)
temp_station <- met_avg$USAFID [which.min (abs(met_avg$temp - temp_median))]
wind_station <- met_avg$USAFID [which.min (abs (met_avg$wind.sp - wind_median))] 
atm_station <- met_avg$USAFID [which.min (abs(met_avg$atm.press - atm_median))]
c(temp_station, wind_station, atm_station)
```
# No they are not coincide, each of them have different id.

# Question 2
```{r}
state_medians <- aggregate(cbind(lat,lon) ~ STATE, data = met_stations, FUN =median, na.rm = TRUE)
state_medians
```

# Question 3
```{r}
state_means <- aggregate(cbind(lat, lon) ~ STATE, data = met_stations, FUN = mean, na.rm = TRUE)
closest_stations <- merge(met_stations, state_means, by = "STATE",suffixes = c("","_mean"))
closest_stations$distance <- sqrt((closest_stations$lat - closest_stations$lat_mean)^2 + 
                                    (closest_stations$lon - closest_stations$lon_mean)^2)
closest_by_state <- do.call(rbind, lapply(split(closest_stations,
                                                closest_stations$STATE), function(x) x[which.min(x$distance), ]))

leaflet() %>%
  addTiles() %>%
  addCircleMarkers(data = state_medians, ~lon, ~lat, color = "blue", 
                   group = "Median Stations", popup = ~STATE) %>%
  addCircleMarkers(data = closest_by_state, ~lon, ~lat, color = "purple", 
                   group = "Closest to Mean", popup = ~STATE) %>%
                   addLayersControl(overlayGroups = c("Median Stations", "Closest to Mean"))
```

# Question 4
```{r}
# Step 1: Calculate state average temperatures (from station averages)
state_temps <- aggregate(temp ~ STATE, data = met_stations, FUN = mean, na.rm = TRUE)

# Step 2: Classify states by temperature
state_temps$temp_cat <- ifelse(state_temps$temp < 20, "low",
                               ifelse(state_temps$temp < 25, "mid", "high"))

# Step 3: Merge original data with state temperature categories
met_with_temp_cat <- merge(met, stations, by.x = "USAFID", by.y = "USAF")
met_with_temp_cat <- merge(met_with_temp_cat, state_temps[, c("STATE", "temp_cat")]
                           , by = "STATE")

# Step 4: Create summary table
# Count unique states by category
num_states <- aggregate(STATE ~ temp_cat, 
                        data=unique (met_with_temp_cat
                                     [, c("STATE", "temp_cat")])
                        , FUN = length)

# Count total records by category
num_records <- aggregate(USAFID ~ temp_cat, data = met_with_temp_cat, 
                         FUN = length)

# Count unique stations by category
num_stations <- aggregate(USAFID ~ temp_cat, 
                          data = unique(met_with_temp_cat
                                        [, c("USAFID", "temp_cat" )])
                          , FUN = length)

# Calculate means by category (this will be weighted by number of records per state)
mean_stats <- aggregate(cbind(temp, wind.sp, atm.press) ~ temp_cat, 
                        data = met_with_temp_cat, FUN = mean, na.rm = TRUE)

# Count NAs by category (using tapply as in your original approach)
na_temp <- tapply(met_with_temp_cat$temp, met_with_temp_cat$temp_cat, function(x) sum(is.na(x))) 
na_wind <- tapply(met_with_temp_cat$wind.sp, met_with_temp_cat$temp_cat, function (x) sum (is.na (x) ))
na_atm <- tapply (met_with_temp_cat$atm.press, met_with_temp_cat$temp_cat, function (x) sum (is.na (x) ))
```
```{r}
# Combine into final summary
final_summary <- data.frame(
  temp_cat = num_states$temp_cat,
  num_states = num_states$STATE,
  num_records = num_records$USAFID,
  num_stations = num_stations$USAFID,
  na_temp = as.numeric(na_temp[num_states$temp_cat]),
  na_wind = as.numeric(na_wind[num_states$temp_cat]),
  na_atm = as.numeric(na_atm[num_states$temp_cat]),
  mean_temp = mean_stats$temp,
  mean_wind_sp = mean_stats$wind.sp,
  mean_atm_press = mean_stats$atm.press)
print (final_summary)
```